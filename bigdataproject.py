# import os
# import shutil
# import random

# # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
# fake_src = "/mnt/data1/pair/mj228/tomesd/tome_images_stable_diffusion"
# real_src = "/mnt/data1/pair/mj228/tomesd/resized_sampled_imagenet3"

# # ëŒ€ìƒ ë””ë ‰í† ë¦¬
# train_fake_dst = "/mnt/data1/pair/mj228/tomesd/Generated_Image_Classification_Min-jeong-LEE/data/train/fake"
# val_fake_dst = "/mnt/data1/pair/mj228/tomesd/Generated_Image_Classification_Min-jeong-LEE/data/validation/fake"
# train_real_dst = "/mnt/data1/pair/mj228/tomesd/Generated_Image_Classification_Min-jeong-LEE/data/train/real"
# val_real_dst = "/mnt/data1/pair/mj228/tomesd/Generated_Image_Classification_Min-jeong-LEE/data/validation/real"

# # ì´ë¯¸ì§€ ë³µì‚¬ í•¨ìˆ˜
# def split_and_copy(src_dir, train_dst, val_dst, seed=42):
#     images = [f for f in os.listdir(src_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
#     assert len(images) >= 2000, f"ğŸ“› {src_dir} ì— 2000ì¥ ë¯¸ë§Œì˜ ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤ (í˜„ì¬ {len(images)}ì¥)."

#     random.seed(seed)
#     random.shuffle(images)

#     train_images = images[:1600]
#     val_images = images[1600:2000]

#     for img in train_images:
#         shutil.copy(os.path.join(src_dir, img), os.path.join(train_dst, img))
#     for img in val_images:
#         shutil.copy(os.path.join(src_dir, img), os.path.join(val_dst, img))

#     print(f"âœ… {src_dir} â†’ {train_dst} (1600ì¥), {val_dst} (400ì¥) ë³µì‚¬ ì™„ë£Œ")

# # ì‹¤í–‰
# split_and_copy(fake_src, train_fake_dst, val_fake_dst)
# split_and_copy(real_src, train_real_dst, val_real_dst)

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
train_dir = "/mnt/data1/pair/mj228/tomesd/Generated_Image_Classification_Min-jeong-LEE/data/train"  # í›ˆë ¨ ë°ì´í„° ê²½ë¡œ
val_dir = "/mnt/data1/pair/mj228/tomesd/Generated_Image_Classification_Min-jeong-LEE/data/validation" # ê²€ì¦ ë°ì´í„° ê²½ë¡œ

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
batch_size = 32
num_epochs = 10
learning_rate = 0.003
num_classes = 2  # fakeì™€ real ë‘ ê°€ì§€ í´ë˜ìŠ¤

# ë°ì´í„° ì „ì²˜ë¦¬: ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ë° ì •ê·œí™”
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),  # ResNet ì…ë ¥ í¬ê¸°
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ë°ì´í„°ì…‹ì˜ í‰ê·  ë° í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
    ]),
    'val': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

# ë°ì´í„°ì…‹ ë¡œë“œ
image_datasets = {
    'train': datasets.ImageFolder(train_dir, data_transforms['train']),
    'val': datasets.ImageFolder(val_dir, data_transforms['val'])
}

# DataLoader ì„¤ì •
dataloaders = {
    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),
    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False)
}

# ResNet ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (pre-trained)
model = models.resnet18(pretrained=True)

# ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ ì¬ì„¤ì •í•˜ì—¬ 2ê°œì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆê²Œ ì„¤ì •
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, num_classes)

# ëª¨ë¸ì„ GPUë¡œ ì˜®ê¸°ê¸° (ê°€ëŠ¥í•œ ê²½ìš°)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

model = model.to(device)

# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜
def train_model_with_history(model, dataloaders, criterion, optimizer, num_epochs=10):
    best_acc = 0.0
    train_loss_history = []
    val_loss_history = []
    train_acc_history = []
    val_acc_history = []

    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}')
        print('-' * 10)

        # ê° epochì—ì„œ í›ˆë ¨ ë° ê²€ì¦ ë‹¨ê³„ ì‹¤í–‰
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •
            else:
                model.eval()   # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

            running_loss = 0.0
            running_corrects = 0

            # ë°ì´í„°ì— ëŒ€í•œ ë°˜ë³µë¬¸
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
                optimizer.zero_grad()

                # ìˆœì „íŒŒ
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # ì—­ì „íŒŒ ë° ìµœì í™” (í›ˆë ¨ ë‹¨ê³„ì—ì„œë§Œ)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # ê¸°ë¡ ì €ì¥
            if phase == 'train':
                train_loss_history.append(epoch_loss)
                train_acc_history.append(epoch_acc.item())
            else:
                val_loss_history.append(epoch_loss)
                val_acc_history.append(epoch_acc.item())

            # ìµœì ì˜ ëª¨ë¸ì„ ì €ì¥
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = model.state_dict()

    print(f'Best val Acc: {best_acc:.4f}')

    # ìµœì ì˜ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ë¡œë“œ
    model.load_state_dict(best_model_wts)
    return model, train_loss_history, val_loss_history, train_acc_history, val_acc_history

# í•™ìŠµ ë° ê²€ì¦ì— ëŒ€í•œ ì†ì‹¤ê³¼ ì •í™•ë„ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
def plot_loss_accuracy(train_loss, val_loss, train_acc, val_acc, num_epochs):
    epochs_range = range(1, num_epochs+1)

# ëª¨ë¸ í•™ìŠµ
model2, train_loss_history, val_loss_history, train_acc_history, val_acc_history = train_model_with_history(
    model, dataloaders, criterion, optimizer, num_epochs=num_epochs)

torch.save(model2.state_dict(), 'best_resnet_model.pth')



# email: mj_lee@korea.ac.kr
# if you have any questions please contact me by email.